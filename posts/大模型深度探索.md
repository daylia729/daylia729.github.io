---
title: 大模型深度探索
description: 大模型深度探索
date: 2025-10-27
tags:
  - 大模型
---


## 预训练阶段
### 数据预处理
https://huggingface.co/datasets/HuggingFaceFW/fineweb
#### 下载并且处理网络数据
<img src="/public/fineweb.png">


#### 分词 tokenization
* text.txt 经过UTF-8编码得到 bits.txt ；8位组合成为一个字节，为了缩短序列长度得到 bytes.txt；进一步缩短序列长度使用byte pair encoding algorithm(BPE),寻找非常常见的连续字节或者符号，将这对组合成一个新符号，多次迭代，每次都可以减少序列的长度，同时增加符号的size。在实践中，符号大约设置为100000。这个将原始文本转换为这些符号的过程称为分词
* 体验一下gpt4的分词器 https://tiktokenizer.vercel.app/?model=cl100k_base
#### 神经网络训练
* 输入是长度可变的词元序列（0~8000），也就是上下文窗口，输出是对下一个词元的预测，which has 10277 probabilities for next token ,the neural network is going to output exactly that many numbers and all of those numbers correspond to the probability of that token as coming next in the sequence.
* llm visualization https://bbycroft.net/llm
